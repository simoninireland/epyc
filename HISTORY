Version 1.2.1

   - Back-ported to work with Python 3.6 and later, and therefore
     with PyPy3

Version 1.1.2 2020-12-02

   - Fixed issue with TypeMapping initialisation
   - Addad ParallelLab for simpler multicore operation
   - Updated tutorials to reflect new opportunities

Version 1.1.1 2020-11-27

   - Fixed ClusterLab.updateResults() not to bail out completely in response
     to a low-level crashed job (which can happen because of engine failure)
   - Slightly more aggressive closing of connection to cluster, since connections
     held open for a long time seem a lot more prone to failure
   - Slight change to the semantics of lambda-expressions in Python3.8 broke
     ClusterLab
   - Dropped support for dill, replaced with automatic use of cloudpickle 
   - Fixed issue with handling RepeatedExperiments
   - Reverted to LabNotebook.addResult() for all additions (splitting between
     addResult() and addResults() caused confusion)
   - Forced pending results job ids to strings, not bytes (needed by ipyparallel)
   - Fixed slightly cavalier attitude towards default (missing) values in ResultSet
   - Added epyc-specific exceptions in places where a programmatic response might
     be appropriate
   - Modified cancellation behaviour to record the job as cancelled rather than
     silently dropping it, to maintain the audit tutorial
   - Added locking of result sets to prevent further changes
   - Added Travis CI integration

Version 1.0.2 2020-11-22

   - Fixed issue with saving notebooks where the default result set was empty
   - Added a test to make sure this was caught :-)

Version 1.0.1 2020-11-16

   - Removed support for Python 2.7
   - Remove test/__main__.py as unnecessary
   - Added result sets to notebooks
   - Changed default behaviour of Experiment.do() to nothing rather than
     raising an exception, as it makes sub-classing easier to describe
   - Replaced explicit Fisher-Yates shuffle of parameter space with
     numpy.random.shuffle() 
   - Moved management of pending results into ResultSet
   - Removed ability to add a result with a job id in LabNotebook.addResult(),
     replaced with LabNotebook.resolvePendingResult()
   - Removed "Managing clusters" from the documentation
   - Added HDF5-based lab notebooks for larger datasets
   - Added storing the classname of an experiment in the metadata
   - Added type annotations 
   - Changed some methods to return empty lists or dicts rather than None
   - Added tutorials on large datasets and Jupyter integration
   - Added new format for JSON storage that handles result sets (while maintaining
     the ability to read the old, flat format)
   - Log information messages to sys.stderr rather than standard output
   - Changed recording of timing information to capture as much as possible
     even if there's an exception in an experiment 
   - Added ``with`` block (context manager) support to notebooks to manage
      committing results (even in the face of exceptions)

Version 0.99.3 2020-03-22

   - Fixed mistake in setup.py that stopped everything building....

Version 0.99.2 2020-03-22

   - Removed scripts as they've been built into ipyparallel
   - Improved tutorial for multicore and clusters, reflecting new ipyparallel
   - Updated requirements to make sure we use latest ipyparallel

Version 0.99.1 2019-05-03

   - Added scripts to simplify creation of clusters

Version 0.15.1 2018-07-12

   - Made compatible with Python 3 as well as Python 2.7

Version 0.14.1 2018-04-18

   - Changed metadata for repeated experiments to retain number of repetitions,
     added the index of each result
   - Eagerly expanded parameter ranges in labs to avoid issues with repeated
     traversal of, for example, ranges

Version 0.13.3 2018-03-27

   - Updated some docstrings that were misleading
   - Tightened-up type checking for variable results argument
   - Re-introduced the use of Dill by default
   
Version 0.13.2 2018-03-23

   - Fixed a bug in adding repeated experiments to notebooks

Version 0.13.1 2018-03-22

   - Got rid of the chunking as there seems to be a race condition
     in ipyparallel or ZeroMQ. A small delay fixes it (for now)
   - Changed the way repeated experiments work, from returning a
     list of results dicts to returning a single one whose results
     were a list of results dicts (so embedding the list one level down)
   - Corresponding changes to summary experiments
   - Added more summary information to summary experiments
   - Removed the default use of dill in ClusterLab
   - ADded documentation for ExperimentCombinator
   
Version 0.12.1 2018-03-09

   - Chunked downloading of pending results from clusters to work around
     some undocumented limits in some database backends 
   - Added slightly improved error handling in summary experiments

Version 0.11.2 2018-03-06

   - Maintenance release changing the build system slightly to allow for
     auto-generation of documentation on readthedocs.io 

Version 0.11.1 2018-03-05

   - Stringified tracebacks so the work better remotely
   - Updated build system somewhat

Version 0.10.1 2016-06-23

   - Added traceback objects to metadata for failed experiments, to help debugging
   - Fixed JSON notebooks to handle tracebacks
   - Added slightly more documentation in places

Version 0.9.1 2016-12-02

   - Changed scale of timing metadata from milliseconds to seconds 
   - Replaced generated doc/conf.py with a static file
   - Added creation of HTML doc ZIP file
   
Version 0.8.1 2016-11-01

   - Added cancellation of pending results to ClusterLab
   - Added Sphinx API documentation
   - Converted class and method docstrings to Sphinx
   - Made labs treat string parameters as single values, not iterables 

Version 0.7.1 2016-08-30

   - Added Lab.dataframe() method to save going to the notebook
   - Added updateResults() at Lab level, removed now-unnecessary
     overriding at ClusterLab level
   - Optimised updateResults() to grab all completed pending results
     in a single network transaction
   - Added global wait() to ClusterLab, coding around the
     ipyparallel.Client code's wait() method (which can't be used
     directly -- see notes in the method)

Version 0.6.2 2016-08-23

   - Oops, forgot to fix one of the changed method names....
   
Version 0.6.1 2016-08-23

   - Refactored experiment combinators
   - Fixed summarisation of non-list-returning experiments

Version 0.5.1

   - Some refactoring
   - Improved exception-handling
   - Fixed integration with JSON persistence

Version 0.4.1 2016-08-12

   - Changed notebooks to keep lists of results for each point in
     their parameter space
   - Improved handling of pending results
   - Allowed addition of lists of results, and experiments that return
     lists of results
   - Made all the classes "new style", based on object
   - Changed Experiment metadata to use datetime objects
   - Added Python datetime <-> ISO datetime string handling to JSON
     notebooks
   - Improved notebook persistence tests
   - Refactored repeated experiments to separate repetition and
     summarisation

Version 0.3.1 2016-07-29

   - Made parameter spaces of a single point work properly
   - Re-wrote Experiment to clean up the logic and allow better
     repetition 

Version 0.2.1 2016-07-28

   - Test suite skips cluster tests if there isn't one running
   - Added repeated experiment combinator
   - Removed SQL-backed notebooks for the time being, until finished

Version 0.1.1 2016-07-15

   - Initial experiment, lab, and notebook implementations
   - Cluster labs
   - Test suite
   - Persistent notebooks to JSON; SQLite outlined but not working
   
